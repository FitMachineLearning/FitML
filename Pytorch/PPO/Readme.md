Simple implementation for PPO, that fixes a few errors. Now runs on pytorch 1.5.0


Credit: nikhilbarhate99

